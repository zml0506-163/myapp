"""
æ–‡ä»¶å¤„ç†æœåŠ¡ - æ”¯æŒå¤šæ ¼å¼ã€ç¼“å­˜ã€å‹ç¼©
app/services/file_service.py
"""
import hashlib
import os
from pathlib import Path
from typing import Optional, List, Dict, Tuple
from PIL import Image
from sqlalchemy import select, func
from openai import OpenAI, NotFoundError

from app.core.config import settings
from app.db.database import get_db_session
from app.models import FileCache


class FileService:
    """æ–‡ä»¶å¤„ç†æœåŠ¡"""

    # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
    SUPPORTED_FORMATS = {
        'image': {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp'},
        'document': {'.txt', '.docx', '.pdf', '.md', '.csv', '.json'},
        'spreadsheet': {'.xlsx'},
        'ebook': {'.epub', '.mobi'}
    }

    def __init__(self):
        self.client = OpenAI(
            api_key=settings.dashscope_api_key,
            base_url=settings.dashscope_base_url,
        )
        self.temp_dir = Path(settings.upload_dir) / "temp"
        self.temp_dir.mkdir(parents=True, exist_ok=True)
        self.MAX_PIXELS = 8190  # åƒç´ é™åˆ¶
        self.MIN_COMPRESS_FILE_SIZE = 2 * 1024 * 1024  # 5MB

    def calculate_file_md5(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶MD5å€¼"""
        md5_hash = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                md5_hash.update(chunk)
        return md5_hash.hexdigest()

    def get_file_type(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶ç±»å‹"""
        ext = Path(file_path).suffix.lower()

        if ext in self.SUPPORTED_FORMATS['image']:
            return 'image'
        elif ext in self.SUPPORTED_FORMATS['document']:
            return 'document'
        elif ext in self.SUPPORTED_FORMATS['spreadsheet']:
            return 'spreadsheet'
        elif ext in self.SUPPORTED_FORMATS['ebook']:
            return 'ebook'
        else:
            return 'unknown'

    def compress_image(self, input_path: str, quality: int = 85) -> str:
        """
        å‹ç¼©å›¾ç‰‡

        Args:
            input_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
            quality: å‹ç¼©è´¨é‡ (1-100)

        Returns:
            å‹ç¼©åçš„å›¾ç‰‡è·¯å¾„
        """
        try:
            output_path = self.temp_dir / f"compressed_{Path(input_path).name}"

            with Image.open(input_path) as img:
                # è½¬æ¢ä¸ºRGBï¼ˆå¤„ç†RGBAç­‰æ ¼å¼ï¼‰
                if img.mode in ('RGBA', 'LA', 'P'):
                    rgb_img = Image.new('RGB', img.size, (255, 255, 255))
                    rgb_img.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                    img = rgb_img

                # å‹ç¼©ä¿å­˜
                img.save(output_path, "JPEG", optimize=True, quality=quality)

            # æ£€æŸ¥å‹ç¼©æ•ˆæœ
            original_size = os.path.getsize(input_path)
            compressed_size = os.path.getsize(output_path)

            print(f"å›¾ç‰‡å‹ç¼©: {original_size / 1024:.1f}KB -> {compressed_size / 1024:.1f}KB")

            # å¦‚æœå‹ç¼©ååè€Œæ›´å¤§ï¼Œä½¿ç”¨åŸå›¾
            if compressed_size >= original_size:
                return input_path

            return str(output_path)

        except Exception as e:
            print(f"å›¾ç‰‡å‹ç¼©å¤±è´¥: {e}")
            return input_path

    def resize_image_by_pixels(self, input_path: str) -> str:
        """è°ƒæ•´å›¾ç‰‡å°ºå¯¸ï¼Œç¡®ä¿å®½/é«˜å‡ä¸è¶…è¿‡MAX_PIXELS"""
        input_path = Path(input_path)
        try:
            with Image.open(input_path) as img:
                width, height = img.size

                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡åƒç´ é™åˆ¶
                if width <= self.MAX_PIXELS and height <= self.MAX_PIXELS:
                    return str(input_path)  # æ— éœ€è°ƒæ•´

                # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆå–æœ€å°æ¯”ä¾‹ï¼Œç¡®ä¿å®½é«˜å‡ä¸è¶…é™ï¼‰
                scale = min(self.MAX_PIXELS / width, self.MAX_PIXELS / height)
                new_width = int(width * scale)
                new_height = int(height * scale)

                # é«˜è´¨é‡ç¼©æ”¾ï¼ˆä¿ç•™åŸå›¾æ¨¡å¼ï¼Œé¿å…ä¸å¿…è¦çš„æ ¼å¼è½¬æ¢ï¼‰
                resized_img = img.resize((new_width, new_height), Image.LANCZOS)

                # ä¿å­˜è°ƒæ•´åçš„å›¾ç‰‡
                output_path = self.temp_dir / f"resized_{input_path.name}"
                # æ ¹æ®åŸå›¾æ ¼å¼ä¿å­˜ï¼ˆä¼˜å…ˆä¿ç•™åŸå›¾æ ¼å¼ï¼‰
                format = img.format or "JPEG"
                resized_img.save(output_path, format=format, optimize=True)

                print(f"å›¾ç‰‡å°ºå¯¸è°ƒæ•´: {width}x{height} -> {new_width}x{new_height}")
                return str(output_path)

        except Exception as e:
            print(f"å›¾ç‰‡å°ºå¯¸è°ƒæ•´å¤±è´¥: {e}")
            return str(input_path)  # å¤±è´¥æ—¶è¿”å›åŸå›¾

    async def verify_file_id(self, file_id: str) -> bool:
        """éªŒè¯qwen-longçš„file_idæ˜¯å¦æœ‰æ•ˆ"""
        try:
            file_info = self.client.files.retrieve(file_id=file_id)
            return file_info.status in ('uploaded', 'completed')
        except NotFoundError:
            return False
        except Exception as e:
            print(f"éªŒè¯file_idå¤±è´¥: {e}")
            return False

    async def get_or_upload_file(self, file_path: str) -> Optional[str]:
        """
        è·å–æˆ–ä¸Šä¼ æ–‡ä»¶åˆ°qwen-long

        ä¼˜å…ˆä»ç¼“å­˜è·å–ï¼Œç¼“å­˜æ— æ•ˆåˆ™é‡æ–°ä¸Šä¼ 

        Returns:
            qwen-longçš„file_id
        """
        # 1. è®¡ç®—MD5
        file_md5 = self.calculate_file_md5(file_path)

        # 2. æŸ¥è¯¢ç¼“å­˜
        async with get_db_session() as db:
            result = await db.execute(
                select(FileCache).where(FileCache.file_md5 == file_md5)
            )
            cached = result.scalar_one_or_none()

            # 3. å¦‚æœæœ‰ç¼“å­˜ï¼ŒéªŒè¯æœ‰æ•ˆæ€§
            if cached and cached.is_valid:
                is_valid = await self.verify_file_id(cached.qwen_file_id)

                if is_valid:
                    # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
                    cached.usage_count += 1
                    cached.last_used_at = func.now()
                    cached.last_verified_at = func.now()
                    await db.commit()

                    print(f"âœ… ä½¿ç”¨ç¼“å­˜æ–‡ä»¶: {cached.original_filename} (file_id: {cached.qwen_file_id})")
                    return cached.qwen_file_id
                else:
                    # æ ‡è®°ä¸ºæ— æ•ˆ
                    cached.is_valid = False
                    await db.commit()

            # 4. ä¸Šä¼ æ–°æ–‡ä»¶
            try:
                # å›¾ç‰‡å‹ç¼©
                file_type = self.get_file_type(file_path)
                upload_path = file_path

                if file_type == 'image':
                    # 1. å…ˆæ£€æŸ¥å¹¶è°ƒæ•´åƒç´ ï¼ˆé¿å…åƒç´ è¶…é™é”™è¯¯ï¼‰
                    resized_path = self.resize_image_by_pixels(file_path)
                    file_size = os.path.getsize(resized_path)

                    # 2. å†æ ¹æ®æ–‡ä»¶å¤§å°å†³å®šæ˜¯å¦å‹ç¼©ï¼ˆå¤§äº5MBåˆ™å‹ç¼©ï¼‰
                    if file_size > self.MIN_COMPRESS_FILE_SIZE:
                        upload_path = self.compress_image(resized_path)
                    else:
                        upload_path = resized_path

                    print(f"ğŸ“¸ å›¾ç‰‡å¤„ç†: {Path(file_path).name} -> {Path(upload_path).name} ({file_size / 1024:.1f}KB)")
                else:
                    print(f"ğŸ“„ å‡†å¤‡ä¸Šä¼ : {Path(file_path).name}")

                # ä¸Šä¼ åˆ°qwen-long
                file_object = self.client.files.create(
                    file=Path(upload_path),
                    purpose="file-extract"
                )

                print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {Path(upload_path).name} -> {file_object.id}")

                # 5. ä¿å­˜åˆ°ç¼“å­˜
                if cached:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    cached.qwen_file_id = file_object.id
                    cached.qwen_status = file_object.status
                    cached.is_valid = True
                    cached.last_verified_at = func.now()
                    cached.usage_count = 1
                    cached.last_used_at = func.now()
                else:
                    # åˆ›å»ºæ–°è®°å½•ï¼ˆä½¿ç”¨åŸå§‹æ–‡ä»¶çš„ä¿¡æ¯ï¼‰
                    new_cache = FileCache(
                        file_md5=file_md5,
                        original_filename=Path(file_path).name,  # ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                        file_path=file_path,  # ä½¿ç”¨åŸå§‹è·¯å¾„
                        file_size=os.path.getsize(file_path),
                        mime_type=None,
                        qwen_file_id=file_object.id,
                        qwen_status=file_object.status,
                        is_valid=True,
                        last_verified_at=func.now(),
                        usage_count=1,
                        last_used_at=func.now()
                    )
                    db.add(new_cache)

                await db.commit()

                return file_object.id

            except Exception as e:
                print(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return None

    async def process_attachments(
            self,
            attachments: List[Dict]
    ) -> Tuple[List[str], bool]:
        """
        å¤„ç†é™„ä»¶åˆ—è¡¨

        Returns:
            (file_idsåˆ—è¡¨, æ˜¯å¦åªæœ‰å›¾ç‰‡)
        """
        file_ids = []
        has_non_image = False

        for att in attachments:
            file_path = att.get('file_path')
            if not file_path or not os.path.exists(file_path):
                continue

            file_type = self.get_file_type(file_path)

            # æ£€æŸ¥æ˜¯å¦æœ‰éå›¾ç‰‡æ–‡ä»¶
            if file_type != 'image':
                has_non_image = True

            # è·å–file_id
            file_id = await self.get_or_upload_file(file_path)
            if file_id:
                file_ids.append(file_id)

        only_images = not has_non_image

        return file_ids, only_images

    async def build_file_context(self, file_ids: List[str]) -> str:
        """æ„å»ºæ–‡ä»¶ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ˆç”¨äºqwen-longçš„systemæ¶ˆæ¯ï¼‰"""
        if not file_ids:
            return ""

        return ",".join([f"fileid://{fid}" for fid in file_ids])

    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            for file in self.temp_dir.glob("compressed_*"):
                if file.is_file():
                    file.unlink()
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


# å…¨å±€å®ä¾‹
file_service = FileService()